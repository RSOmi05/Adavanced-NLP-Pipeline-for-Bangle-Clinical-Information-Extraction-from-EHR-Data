{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b96440c-540e-44d3-9bb4-66b5486314ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All packages installed and imported successfully!\n",
      "Initializing Complete Clinical Information Extraction System...\n",
      "System initialized successfully!\n",
      "\n",
      "TEXT NORMALIZATION DEMONSTRATION\n",
      "==================================================\n",
      "Original 1: ডাঃ রহমান রাঃ ৩৫ বছর বয়সী পুরুষ জ্বর ও মাথা ব্যথায় ভুগছেন।\n",
      "Normalized: ডাক্তার রহমান রোগী 35 বছর বয়সী পুরুষ জ্বর ও মাথাব্যথা ভুগছেন\n",
      "------------------------------\n",
      "Original 2: তাপমাত্রা ১০২.৫° ফারেনহাইট। পিE: সাধারণ অবস্থা ভাল।\n",
      "Normalized: তাপমাত্রা 102.5 ফারেনহাইট পি: সাধারণ অবস্থা ভাল\n",
      "------------------------------\n",
      "Original 3: এ/পি: প্যারাসিটামল ৫০০ মিগ্র দিনে ৩ বার ৫ দিন।\n",
      "Normalized: এ/পি: প্যারাসিটামল 500 মিগ্র দিনে 3 বার 5 দিন\n",
      "------------------------------\n",
      "\n",
      "TOKENIZATION DEMONSTRATION\n",
      "==================================================\n",
      "Original: রোগী জ্বর ও মাথাব্যথায় ভুগছেন। তাপমাত্রা ১০২.৫ ডিগ্রি। প্যারাসিটামল ৫০০ মিলিগ্রাম দিনে ৩ বার।\n",
      "\n",
      "Sentences: ['রোগী জ্বর ও মাথাব্যথায় ভুগছেন', 'তাপমাত্রা ১০২.৫ ডিগ্রি', 'প্যারাসিটামল ৫০০ মিলিগ্রাম দিনে ৩ বার']\n",
      "\n",
      "Tokens: ['রোগী', 'জ্বর', 'ও', 'মাথাব্যথায়', 'ভুগছেন।', 'তাপমাত্রা', '১০২.৫ ডিগ্রি।', 'প্যারাসিটামল', '৫০০ মিলিগ্রাম', 'দিনে', '৩', 'বার।']\n",
      "\n",
      "ENTITY RECOGNITION DEMONSTRATION\n",
      "==================================================\n",
      "Text: ৩৫ বছর বয়সী পুরুষ রোগী জ্বর ও মাথাব্যথায় ভুগছেন।\n",
      "তাপমাত্রা ১০২ ডিগ্রি ফারেনহাইট। রক্তচাপ ১৪০/৯০।\n",
      "প্যারাসিটামল ৫০০ মিলিগ্রাম দিনে ৩ বার ৫ দিন সেবন করুন।\n",
      "রক্ত পরীক্ষা ও প্রস্রাব পরীক্ষা করাতে হবে।\n",
      "\n",
      "Extracted Entities:\n",
      "SYMPTOM: ['জ্বর']\n",
      "MEDICATION: ['প্যারাসিটামল']\n",
      "DOSAGE: ['৫০০ মিলিগ্রাম']\n",
      "FREQUENCY: ['দিনে ৩ বার']\n",
      "MEDICATION_DURATION: ['৫ দিন সেবন']\n",
      "VITAL_SIGN: ['তাপমাত্রা ১০২ ডিগ্রি', 'রক্তচাপ ১৪০/৯০']\n",
      "TEST: ['রক্ত পরীক্ষা', 'প্রস্রাব পরীক্ষা']\n",
      "AGE: ['৩৫ বছর বয়সী']\n",
      "GENDER: ['পুরুষ']\n",
      "\n",
      "RELATION EXTRACTION DEMONSTRATION\n",
      "==================================================\n",
      "Text: রোগী জ্বর ও মাথাব্যথায় ভুগছেন। জ্বর থেকে দুর্বলতা হয়েছে।\n",
      "প্যারাসিটামল ৫০০ মিলিগ্রাম দিনে ৩ বার ৫ দিন সেবন করুন।\n",
      "ওষুধ খাওয়ার পরে জ্বর কমবে।\n",
      "\n",
      "General Relations:\n",
      "  symptom_of: রোগী জ্বর ও মাথাব্যথায় ভুগছেন। জ্বর → দুর্বলতা (conf: 1.00)\n",
      "  has_dosage: প্যারাসিটামল → ৫০০ (conf: 1.00)\n",
      "  has_frequency: প্যারাসিটামল ৫০০ মিলিগ্রাম → দিনে (conf: 1.00)\n",
      "  medication_has_duration: প্যারাসিটামল ৫০০ মিলিগ্রাম দিনে ৩ বার → ৫ (conf: 1.00)\n",
      "  temporal_since: রোগী জ্বর ও মাথাব্যথায় ভুগছেন। জ্বর → দ (conf: 1.00)\n",
      "\n",
      "Medication Relations:\n",
      "  has_dosage: প্যারাসিটামল → ৫০০ মিলিগ্রাম\n",
      "  has_frequency: প্যারাসিটামল → দিনে ৩ বার\n",
      "  has_medication_duration: প্যারাসিটামল → ৫ দিন সেবন\n",
      "\n",
      "======================================================================\n",
      "COMPLETE CLINICAL INFORMATION EXTRACTION DEMONSTRATION\n",
      "======================================================================\n",
      "\n",
      "Processing sample clinical texts:\n",
      "==================================================\n",
      "\n",
      "Document 1:\n",
      "Input: রোগী আব্দুর রহমান ৩৫ বছর বয়সী পুরুষ গত ২ দিন ধরে জ্বর এবং মাথাব্যথায় ভুগছেন। তাপমাত্রা ১০২ ডিগ্রি। প্যারাসিটামল ৫০০ মিলিগ্রাম দিনে ৩ বার ৩ দিন খেতে দিয়েছি।\n",
      "Patient Name: আব্দুর রহমান\n",
      "Age: 35 বছর বয়সী\n",
      "Symptoms: ['জ্বর', 'মাথাব্যথা']\n",
      "Diseases: []\n",
      "Medications: [{'name': 'প্যারাসিটামল', 'dosage': '500 মিলিগ্রাম', 'frequency': 'দিনে 3 বার', 'duration': '3 দিন খেতে'}]\n",
      "Duration of Condition: গত 2 দিন ধরে\n",
      "Diagnostic Tests: []\n",
      "Vital Signs: ['তাপমাত্রা 102 ডিগ্রি']\n",
      "Processing Time: 0.011s\n",
      "\n",
      "Document 2:\n",
      "Input: রোগী ফাতিমা খাতুন ৪৫ বছর বয়সী মহিলা রক্তচাপ ১৪০/৯০। ডায়াবেটিসের ইতিহাস আছে। ওজন ৬৫ কেজি। মেটফরমিন ৫০০ মিলিগ্রাম দিনে ২ বার।\n",
      "Patient Name: ফাতিমা খাতুন\n",
      "Age: 45 বছর বয়সী\n",
      "Symptoms: []\n",
      "Diseases: ['ডায়াবেটিস']\n",
      "Medications: [{'name': 'মেটফরমিন', 'dosage': '500 মিলিগ্রাম', 'frequency': 'দিনে 2 বার', 'duration': None}]\n",
      "Duration of Condition: None\n",
      "Diagnostic Tests: []\n",
      "Vital Signs: ['রক্তচাপ 140/90']\n",
      "Processing Time: 0.007s\n",
      "\n",
      "Document 3:\n",
      "Input: ৮ বছর বয়সী ছেলে শিশুর গত ৩ দিন ধরে জ্বর ও কাশি। পরীক্ষা: রক্ত পরীক্ষা, এক্স রে। ওষুধ: প্যারাসিটামল ২৫০ মিলিগ্রাম দিনে ৩ বার\n",
      "Patient Name: None\n",
      "Age: 8 বছর বয়সী\n",
      "Symptoms: ['জ্বর']\n",
      "Diseases: []\n",
      "Medications: [{'name': 'প্যারাসিটামল', 'dosage': '250 মিলিগ্রাম', 'frequency': 'দিনে 3 বার', 'duration': None}]\n",
      "Duration of Condition: গত 3 দিন ধরে\n",
      "Diagnostic Tests: ['রক্ত পরীক্ষা', 'এক্স রে']\n",
      "Vital Signs: []\n",
      "Processing Time: 0.007s\n",
      "\n",
      "Document 4:\n",
      "Input: রোগী জ্বর এবং মাথাব্যথায় ভুগছেন। তাপমাত্রা ১০২ ডিগ্রি। প্যারাসিটামল ৫০০ মিলিগ্রাম দিনে ২ বার ৩ দিন খেতে দিয়েছি।\n",
      "Patient Name: None\n",
      "Age: None\n",
      "Symptoms: ['জ্বর', 'মাথাব্যথা']\n",
      "Diseases: []\n",
      "Medications: [{'name': 'প্যারাসিটামল', 'dosage': '500 মিলিগ্রাম', 'frequency': 'দিনে 2 বার', 'duration': '3 দিন খেতে'}]\n",
      "Duration of Condition: None\n",
      "Diagnostic Tests: []\n",
      "Vital Signs: ['তাপমাত্রা 102 ডিগ্রি']\n",
      "Processing Time: 0.005s\n",
      "\n",
      "Document 5:\n",
      "Input: রক্তচাপ ১৪০/৯০। ডায়াবেটিসের ইতিহাস আছে। মেটফরমিন ৫০০ মিলিগ্রাম দিনে ২ বার।\n",
      "Patient Name: None\n",
      "Age: None\n",
      "Symptoms: []\n",
      "Diseases: ['ডায়াবেটিস']\n",
      "Medications: [{'name': 'মেটফরমিন', 'dosage': '500 মিলিগ্রাম', 'frequency': 'দিনে 2 বার', 'duration': None}]\n",
      "Duration of Condition: None\n",
      "Diagnostic Tests: []\n",
      "Vital Signs: ['রক্তচাপ 140/90']\n",
      "Processing Time: 0.002s\n",
      "\n",
      "Document 6:\n",
      "Input: পেটব্যথা এবং বমি। গত ৩ দিন ধরে সমস্যা। ওমিপ্রাজল ২০ মিলিগ্রাম সকালে খালি পেটে।\n",
      "Patient Name: None\n",
      "Age: None\n",
      "Symptoms: ['পেটব্যথা', 'বমি']\n",
      "Diseases: []\n",
      "Medications: [{'name': 'ওমিপ্রাজল', 'dosage': '20 মিলিগ্রাম', 'frequency': None, 'duration': None}]\n",
      "Duration of Condition: গত 3 দিন ধরে\n",
      "Diagnostic Tests: []\n",
      "Vital Signs: []\n",
      "Processing Time: 0.002s\n",
      "\n",
      "Document 7:\n",
      "Input: ৪৫ বছর বয়সী মহিলা ডায়াবেটিস এবং উচ্চরক্তচাপে আক্রান্ত। ইনসুলিন ২০ ইউনিট দিনে ২ বার সকালে ও রাতে খেতে বলা হয়েছে। ওজন ৬৮ কেজি।\n",
      "Patient Name: None\n",
      "Age: 45 বছর বয়সী\n",
      "Symptoms: []\n",
      "Diseases: ['ডায়াবেটিস']\n",
      "Medications: [{'name': 'ইনসুলিন', 'dosage': '20 ইউনিট', 'frequency': 'দিনে 2 বার', 'duration': None}]\n",
      "Duration of Condition: None\n",
      "Diagnostic Tests: []\n",
      "Vital Signs: []\n",
      "Processing Time: 0.008s\n",
      "\n",
      "Document 8:\n",
      "Input: ৩২ বছর বয়সী পুরুষ পেটব্যথা ও বমির জন্য ভর্তি ছিলেন। অ্যামক্সিসিলিন ৫০০ মিলিগ্রাম দিনে ৩ বার ৭ দিন সেবন করতে হয়েছে। প্রস্রাব পরীক্ষা ও আল্ট্রাসাউন্ড করানো হয়েছে।\n",
      "Patient Name: None\n",
      "Age: 32 বছর বয়সী\n",
      "Symptoms: ['পেটব্যথা', 'বমি']\n",
      "Diseases: []\n",
      "Medications: [{'name': 'অ্যামক্সিসিলিন', 'dosage': '500 মিলিগ্রাম', 'frequency': 'দিনে 3 বার', 'duration': '7 দিন সেবন'}]\n",
      "Duration of Condition: None\n",
      "Diagnostic Tests: ['প্রস্রাব পরীক্ষা', 'আল্ট্রাসাউন্ড']\n",
      "Vital Signs: []\n",
      "Processing Time: 0.014s\n",
      "\n",
      "Document 9:\n",
      "Input: ৬০ বছর বয়সী পুরুষ হৃদরোগে ভুগছেন। কুইনাপ্রিল ৭৫ মিলিগ্রাম প্রতিদিন। রক্তচাপ ১৫০/১০০ mmHg.\n",
      "Patient Name: None\n",
      "Age: 60 বছর বয়সী\n",
      "Symptoms: []\n",
      "Diseases: ['হৃদরোগ']\n",
      "Medications: [{'name': 'কুইনাপ্রিল', 'dosage': '75 মিলিগ্রাম', 'frequency': None, 'duration': None}]\n",
      "Duration of Condition: None\n",
      "Diagnostic Tests: []\n",
      "Vital Signs: ['রক্তচাপ 150/100']\n",
      "Processing Time: 0.002s\n",
      "\n",
      "System Statistics:\n",
      "total_requests: 9\n",
      "cache_size: 9\n",
      "cache_hit_ratio: 0.0\n",
      "avg_processing_time: 0.006450282202826606\n",
      "\n",
      "==================================================\n",
      "EVALUATION FRAMEWORK DEMONSTRATION\n",
      "==================================================\n",
      "\n",
      "Entity Extraction Evaluation Results:\n",
      "SYMPTOM: P=1.000, R=0.200, F1=0.333\n",
      "MEDICATION: P=1.000, R=0.500, F1=0.667\n",
      "DISEASE: P=0.000, R=0.000, F1=0.000\n",
      "macro_avg: P=0.667, R=0.233, F1=0.333\n",
      "\n",
      "Complete Bangla Clinical Information Extraction Protocol demonstrated successfully!\n",
      "\n",
      "======================================================================\n",
      "PROTOCOL SUMMARY\n",
      "======================================================================\n",
      "Text Normalization - Unicode, digit standardization, abbreviation expansion\n",
      "Clinical Tokenization - Medical compound handling, sentence segmentation\n",
      "Entity Recognition - Rule-based + dictionary-based extraction\n",
      "Relation Extraction - Clinical and temporal relationship patterns\n",
      "Complete Pipeline - End-to-end clinical information structuring\n",
      "Evaluation Framework - Precision, recall, F1-score metrics\n",
      "Performance Optimization - Caching, statistics tracking\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Enhanced Bangla Clinical Information Extraction from Electronic Health Records (EHRs)\n",
    "# Complete Implementation Protocol and Framework with All Requested Modifications\n",
    "\"\"\"\n",
    "# Enhanced Bangla Clinical Information Extraction Protocol\n",
    "## Key Enhancements:\n",
    "1. Improved patient name extraction (proper Bengali names only)\n",
    "2. Added weight (kg) and gender (male/female) extraction\n",
    "3. Enhanced diagnostic test extraction\n",
    "4. Comprehensive disease entity recognition\n",
    "5. Added prior medical history extraction\n",
    "6. Clear separation between condition duration and medication duration\n",
    "7. Improved symptom extraction\n",
    "8. Enhanced medication detail extraction\n",
    "\"\"\"\n",
    "\n",
    "# ==========================================\n",
    "# SECTION 1: INSTALLATION AND IMPORTS\n",
    "# ==========================================\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_packages():\n",
    "    packages = [\n",
    "        'transformers', 'torch', 'pandas', 'numpy', 'scikit-learn',\n",
    "        'datasets', 'seqeval', 'plotly', 'matplotlib', 'seaborn'\n",
    "    ]\n",
    "    for package in packages:\n",
    "        try:\n",
    "            __import__(package)\n",
    "        except ImportError:\n",
    "            subprocess.check_call([sys.executable, '-m', 'pip', 'install', package])\n",
    "\n",
    "install_packages()\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "import hashlib\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Tuple, Optional, Any\n",
    "import logging\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "import unicodedata\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import time\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "print(\"All packages installed and imported successfully!\")\n",
    "\n",
    "# ==========================================\n",
    "# SECTION 2: DATA COLLECTION PROTOCOL\n",
    "# ==========================================\n",
    "class BanglaClinicalDataCollector:\n",
    "    \"\"\"\n",
    "    Enhanced protocol for collecting and organizing Bangla clinical data from various sources\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.data_sources = {\n",
    "            'hospital_ehr': 'Electronic Health Records from hospitals',\n",
    "            'clinic_notes': 'Clinical notes from private clinics',\n",
    "            'discharge_summaries': 'Patient discharge summaries',\n",
    "            'prescription_notes': 'Prescription and medication records',\n",
    "            'lab_reports': 'Laboratory test reports with interpretations',\n",
    "            'consultation_notes': 'Doctor-patient consultation records'\n",
    "        }\n",
    "        self.data_types = {\n",
    "            'patient_name': 'Patient identification',\n",
    "            'age': 'Patient age information',\n",
    "            'gender': 'Patient gender (male/female)',\n",
    "            'weight': 'Patient weight in kg',\n",
    "            'chief_complaint': 'Primary reason for visit',\n",
    "            'history_present_illness': 'Current illness description',\n",
    "            'past_medical_history': 'Previous medical conditions',\n",
    "            'medications': 'Current and prescribed medications',\n",
    "            'physical_examination': 'Physical exam findings',\n",
    "            'assessment_plan': 'Diagnosis and treatment plan',\n",
    "            'diagnostic_tests': 'Laboratory and imaging tests'\n",
    "        }\n",
    "\n",
    "    def create_data_collection_guidelines(self):\n",
    "        \"\"\"Create comprehensive data collection guidelines\"\"\"\n",
    "        guidelines = {\n",
    "            'inclusion_criteria': [\n",
    "                'Native Bangla clinical text',\n",
    "                'Complete patient records with all sections',\n",
    "                'Verified by medical professionals',\n",
    "                'Covers diverse medical specialties',\n",
    "                'Includes various complexity levels',\n",
    "                'Contains proper patient demographics'\n",
    "            ],\n",
    "            'exclusion_criteria': [\n",
    "                'Incomplete or corrupted records',\n",
    "                'Non-clinical administrative text',\n",
    "                'Heavily code-mixed text (>50% English)',\n",
    "                'Records with patient identifying information',\n",
    "                'Records without essential clinical information'\n",
    "            ],\n",
    "            'quality_standards': [\n",
    "                'Minimum 500 characters per document',\n",
    "                'Clear, readable handwriting (if scanned)',\n",
    "                'Proper sentence structure',\n",
    "                'Medical terminology consistency',\n",
    "                'Temporal information included',\n",
    "                'Complete demographic information'\n",
    "            ],\n",
    "            'annotation_guidelines': [\n",
    "                'BIO tagging scheme for entities',\n",
    "                'Standardized entity type definitions',\n",
    "                'Inter-annotator agreement >0.8',\n",
    "                'Medical expert validation',\n",
    "                'Quality control checkpoints',\n",
    "                'Separate annotation for condition vs medication duration'\n",
    "            ]\n",
    "        }\n",
    "        return guidelines\n",
    "\n",
    "# ==========================================\n",
    "# SECTION 3: ENHANCED TEXT PREPROCESSING AND NORMALIZATION\n",
    "# ==========================================\n",
    "class BanglaTextNormalizer:\n",
    "    \"\"\"\n",
    "    Enhanced comprehensive text normalization for Bangla clinical text\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.bangla_to_arabic_digits = str.maketrans('০১২৩৪৫৬৭৮৯', '0123456789')\n",
    "        self.clinical_abbreviations = {\n",
    "            'ডাঃ': 'ডাক্তার',\n",
    "            'রাঃ': 'রোগী',\n",
    "            'সিসিঃ': 'প্রধান অভিযোগ',\n",
    "            'এইচপিআইঃ': 'বর্তমান অসুস্থতার ইতিহাস',\n",
    "            'পিএমএইচঃ': 'পূর্ববর্তী চিকিৎসা ইতিহাস',\n",
    "            'পিইঃ': 'শারীরিক পরীক্ষা',\n",
    "            'এ/পিঃ': 'মূল্যায়ন ও পরিকল্পনা',\n",
    "            'কেজিঃ': 'কেজি',\n",
    "            'কিলোগ্রামঃ': 'কিলোগ্রাম'\n",
    "        }\n",
    "\n",
    "        # Enhanced medical term standardization\n",
    "        self.medical_variants = {\n",
    "            'জ্বর': ['জর', 'জ্বর', 'জ্বড়', 'জরে'],\n",
    "            'মাথাব্যথা': ['মাথা ব্যথা', 'মাথাব্যাথা', 'মাথার ব্যথা', 'মাথা যন্ত্রণা', 'মাথাব্যথায়'],\n",
    "            'কাশি': ['কাশি','কাসি', 'কাশী', 'কাসী', 'কাশ', 'কাশিতে'],\n",
    "            'শ্বাসকষ্ট': ['শাসকষ্ট', 'শ্বাস কষ্ট', 'নিঃশ্বাস কষ্ট', 'দম বন্ধ', 'দমবন্ধ'],\n",
    "            'পেটব্যথা': ['পেট ব্যথা', 'পেটে ব্যথা', 'পেটব্যথায়', 'উদর ব্যথা', 'পেট যন্ত্রণা', 'পেটে যন্ত্রণা'],\n",
    "            'বমি': ['বমী', 'বমন', 'বমিভাব', 'বমির'],\n",
    "            'ডায়াবেটিস': ['ডায়েবেটিস', 'ডায়াবেটিস', 'ডাইবেটিস','বহুমূত্র', 'মধুমেহ', 'ডায়াবেটিক','ডাইবেটিসে','ডায়াবেটিসে', 'ডায়াবেটিসের'],\n",
    "            'উচ্চরক্তচাপ': ['হাই প্রেশার', 'উচ্চরক্তচাপ', 'উচ্চ রক্তচাপ', 'উচ্চ রক্ত চাপ', 'হাইপারটেনশন', 'উচ্চ রক্তচাপে', 'উচ্চরক্তচাপে'],\n",
    "            'হৃদরোগ': ['হার্টের রোগ', 'হৃদয়ের রোগ', 'কার্ডিয়াক', 'হৃদরোগে']\n",
    "        }\n",
    "\n",
    "    def normalize_unicode(self, text: str) -> str:\n",
    "        \"\"\"Normalize Unicode representations to standard form\"\"\"\n",
    "        return unicodedata.normalize('NFC', text)\n",
    "\n",
    "    def standardize_digits(self, text: str) -> str:\n",
    "        \"\"\"Convert Bangla digits to Arabic numerals\"\"\"\n",
    "        return text.translate(self.bangla_to_arabic_digits)\n",
    "\n",
    "    def expand_abbreviations(self, text: str) -> str:\n",
    "        \"\"\"Expand common clinical abbreviations\"\"\"\n",
    "        for abbrev, expansion in self.clinical_abbreviations.items():\n",
    "            text = text.replace(abbrev, expansion)\n",
    "        return text\n",
    "\n",
    "    def standardize_medical_terms(self, text: str) -> str:\n",
    "        \"\"\"Standardize medical term variations\"\"\"\n",
    "        for standard, variants in self.medical_variants.items():\n",
    "            for variant in variants:\n",
    "                text = text.replace(variant, standard)\n",
    "        return text\n",
    "\n",
    "    def remove_noise(self, text: str) -> str:\n",
    "        \"\"\"Remove irrelevant characters while preserving clinical punctuation\"\"\"\n",
    "        # Remove excessive whitespace\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        # Keep Bangla characters, digits, and essential punctuation\n",
    "        text = re.sub(r'[^\\u0980-\\u09FF\\s\\.\\,\\:\\;\\-\\(\\)\\d\\+\\=\\/\\%]', '', text)\n",
    "        return text.strip()\n",
    "\n",
    "    def process(self, text: str) -> str:\n",
    "        \"\"\"Complete normalization pipeline\"\"\"\n",
    "        if not text:\n",
    "            return \"\"\n",
    "        text = self.normalize_unicode(text)\n",
    "        text = self.expand_abbreviations(text)\n",
    "        text = self.standardize_medical_terms(text)\n",
    "        text = self.standardize_digits(text)\n",
    "        text = self.remove_noise(text)\n",
    "        return text\n",
    "\n",
    "# ==========================================\n",
    "# SECTION 4: ENHANCED CLINICAL TOKENIZATION\n",
    "# ==========================================\n",
    "class BanglaClinicalTokenizer:\n",
    "    \"\"\"\n",
    "    Enhanced specialized tokenizer for Bangla clinical text\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.medical_compounds = {\n",
    "            'রক্ত চাপ': 'রক্তচাপ',\n",
    "            'হৃদ রোগ': 'হৃদরোগ',\n",
    "            'চোখ ব্যথা': 'চোখব্যথা',\n",
    "            'পেট ব্যথা': 'পেটব্যথা',\n",
    "            'মাথা ব্যথা': 'মাথাব্যথা',\n",
    "            'রক্ত পরীক্ষা': 'রক্ত_পরীক্ষা',\n",
    "            'প্রস্রাব পরীক্ষা': 'প্রস্রাব_পরীক্ষা',\n",
    "            'এক্স রে': 'এক্স_রে'\n",
    "        }\n",
    "\n",
    "        # Medical measurement patterns\n",
    "        self.measurement_patterns = [\n",
    "            r'\\d+\\.?\\d*\\s*(?:মিলিগ্রাম|গ্রাম|মিলি|ট্যাবলেট|ক্যাপসুল |ইউনিট)',\n",
    "            r'\\d+\\.?\\d*\\s*(?:ডিগ্রি|°)',\n",
    "            r'\\d+\\/\\d+\\s*(?:mmHg|মিমি)'\n",
    "        ]\n",
    "\n",
    "    def segment_sentences(self, text: str) -> List[str]:\n",
    "        \"\"\"Clinical-aware sentence segmentation\"\"\"\n",
    "        # Protect decimal numbers and measurements\n",
    "        text = re.sub(r'(\\d+)\\.(\\d+)', r'\\1DECIMAL\\2', text)\n",
    "        # Protect medical abbreviations\n",
    "        text = re.sub(r'(ডাঃ|রাঃ|সিসিঃ)', r'\\1ABBREV', text)\n",
    "        # Split on sentence boundaries\n",
    "        sentences = re.split(r'[।\\.!?]+', text)\n",
    "        # Restore protected elements and clean\n",
    "        sentences = [s.replace('DECIMAL', '.').replace('ABBREV', '').strip()\n",
    "                    for s in sentences if s.strip()]\n",
    "        return sentences\n",
    "\n",
    "    def tokenize_words(self, text: str) -> List[str]:\n",
    "        \"\"\"Word tokenization with medical compound handling\"\"\"\n",
    "        # Handle medical compounds first\n",
    "        for compound, merged in self.medical_compounds.items():\n",
    "            text = text.replace(compound, merged)\n",
    "\n",
    "        # Protect measurements\n",
    "        for pattern in self.measurement_patterns:\n",
    "            text = re.sub(pattern, lambda m: m.group().replace(' ', '_SPACE_'), text)\n",
    "\n",
    "        # Basic word tokenization\n",
    "        tokens = re.findall(r'\\S+', text)\n",
    "\n",
    "        # Restore spaces in measurements\n",
    "        tokens = [token.replace('_SPACE_', ' ') for token in tokens]\n",
    "        return tokens\n",
    "\n",
    "# ==========================================\n",
    "# SECTION 5: ENHANCED ENTITY RECOGNITION SYSTEM\n",
    "# ==========================================\n",
    "class EnhancedClinicalEntityRecognizer:\n",
    "    \"\"\"\n",
    "    Enhanced rule-based and dictionary-based clinical entity recognition\n",
    "    \"\"\"\n",
    "    def __init__(self, lexicon_path: Optional[str] = None):\n",
    "        self.entity_patterns = self._compile_patterns()\n",
    "        self.lexicons = self._load_lexicons(lexicon_path) if lexicon_path else self._enhanced_lexicons()\n",
    "        self.name_patterns = self._compile_name_patterns()\n",
    "\n",
    "    def _enhanced_lexicons(self) -> Dict[str, set]:\n",
    "        \"\"\"Enhanced medical lexicons for Bangla clinical terms\"\"\"\n",
    "        return {\n",
    "            'symptoms': {\n",
    "                'জ্বর', 'মাথাব্যথা', 'মাথাব্যথায়' ' কাশি', 'শ্বাসকষ্ট', 'বমি', 'ডায়রিয়া', 'পেটব্যথা',\n",
    "                'চোখব্যথা', 'গলাব্যথা', 'অরুচি', 'দুর্বলতা', 'মাথাঘোরা', 'বুকব্যথা',\n",
    "                'হাঁপানি', 'কোষ্ঠকাঠিন্য', 'অনিদ্রা', 'ক্লান্তি', 'বুক ধড়ফড়ানি',\n",
    "                'পিঠব্যথা', 'কানব্যথা', 'দাঁতব্যথা', 'জয়েন্টে ব্যথা', 'পায়ে ব্যথা',\n",
    "                'হাতে ব্যথা', 'ঘাড়ব্যথা', 'কোমর ব্যথা', 'বুক জ্বালা', 'গ্যাস',\n",
    "                'এসিডিটি', 'বদহজম', 'মুখ শুকিয়ে যাওয়া', 'প্রস্রাবে জ্বালা', 'বুক ধড়ফড়ানি'\n",
    "            },\n",
    "            'diseases': {\n",
    "                'ডায়াবেটিস', 'হৃদরোগ', 'উচ্চ রক্তচাপ', 'যক্ষ্মা', 'ক্যান্সার', 'অ্যাজমা',\n",
    "                'আর্থ্রাইটিস', 'হেপাটাইটিস', 'ম্যালেরিয়া', 'টাইফয়েড', 'নিউমোনিয়া',\n",
    "                'ব্রংকাইটিস', 'গ্যাস্ট্রাইটিস', 'আলসার', 'কিডনি রোগ', 'লিভার রোগ',\n",
    "                'থাইরয়েড', 'মাইগ্রেন', 'সাইনাস', 'টনসিল', 'গলব্লাডার স্টোন',\n",
    "                'কিডনি স্টোন', 'অ্যাপেন্ডিসাইটিস', 'কলেরা', 'ডেঙ্গু', 'চিকনগুনিয়া',\n",
    "                'ভাইরাল ফিভার', 'ইনফেকশন', 'এলার্জি', 'একজিমা', 'সোরিয়াসিস'\n",
    "            },\n",
    "            'medications': {\n",
    "                'প্যারাসিটামল', 'ইনসুলিন', 'অ্যান্টিবায়োটিক', 'অ্যান্টাসিড', 'আইবুপ্রোফেন',\n",
    "                'মেটফরমিন', 'অ্যামক্সিসিলিন', 'ওমিপ্রাজল', 'এসপিরিন', 'প্রেডনিসোলন',\n",
    "                'ফুরোসেমাইড', 'এটোরভাস্ট্যাটিন', 'লসার্টান', 'এমলোডিপিন', 'র্যানিটিডিন',\n",
    "                'ডোমপেরিডন', 'সিপ্রোফ্লক্সাসিন', 'ডক্সিসাইক্লিন', 'সেফট্রিয়াক্সন', 'কুইনাপ্রিল',\n",
    "                'নাপা', 'স্কয়ার', 'বেক্সিমকো', 'এসকে ফার্মা', 'রেনাটা', 'ইনসেপ্টা'\n",
    "            },\n",
    "            'body_parts': {\n",
    "                'মাথা', 'চোখ', 'নাক', 'গলা', 'বুক', 'পেট', 'হাত', 'পা', 'হৃদয়',\n",
    "                'ফুসফুস', 'কিডনি', 'লিভার', 'মস্তিষ্ক', 'হাড়', 'জয়েন্ট', 'মেরুদণ্ড',\n",
    "                'কান', 'দাঁত', 'জিহ্বা', 'গলা', 'ঘাড়', 'কাঁধ', 'কনুই', 'কব্জি',\n",
    "                'পিঠ', 'কোমর', 'নিতম্ব', 'জানু', 'গোড়ালি', 'পায়ের আঙুল', 'হাতের আঙুল'\n",
    "            },\n",
    "            'tests': {\n",
    "                'রক্ত পরীক্ষা', 'প্রস্রাব পরীক্ষা', 'এক্স রে', 'ইসিজি', 'আল্ট্রাসাউন্ড',\n",
    "                'সিটি স্ক্যান', 'এমআরআই', 'এন্ডোস্কোপি', 'কলোনস্কোপি', 'ইকো',\n",
    "                'স্ট্রেস টেস্ট', 'গ্লুকোজ টেস্ট', 'এইচবিএ ওয়ানসি', 'লিপিড প্রোফাইল',\n",
    "                'থাইরয়েড ফাংশন টেস্ট', 'লিভার ফাংশন টেস্ট', 'কিডনি ফাংশন টেস্ট',\n",
    "                'বায়োপসি', 'মেমোগ্রাম', 'প্যাপ স্মিয়ার', 'স্পুটাম টেস্ট'\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def _load_lexicons(self, lexicon_path: str) -> Dict[str, set]:\n",
    "        \"\"\"Load lexicons from JSON file\"\"\"\n",
    "        try:\n",
    "            with open(lexicon_path, 'r', encoding='utf-8') as f:\n",
    "                lexicons_data = json.load(f)\n",
    "            return {key: set(value) for key, value in lexicons_data.items()}\n",
    "        except FileNotFoundError:\n",
    "            logger.warning(f\"Lexicon file not found at {lexicon_path}. Using default lexicons.\")\n",
    "            return self._enhanced_lexicons()\n",
    "        except json.JSONDecodeError:\n",
    "            logger.warning(f\"Error decoding lexicon JSON from {lexicon_path}. Using default lexicons.\")\n",
    "            return self._enhanced_lexicons()\n",
    "        except Exception as e:\n",
    "            logger.error(f\"An error occurred loading lexicons: {e}. Using default lexicons.\")\n",
    "            return self._enhanced_lexicons()\n",
    "\n",
    "\n",
    "    def _compile_patterns(self) -> Dict[str, re.Pattern]:\n",
    "        \"\"\"Compile regex patterns for clinical entities\"\"\"\n",
    "        return {\n",
    "            # Enhanced patient name patterns - more specific for Bengali names\n",
    "            # Corrected pattern for Bengali characters using Unicode range\n",
    "            'patient_name': re.compile(r'(?:রোগী[ঃ:]?\\s*|নাম[ঃ:]?\\s*|Patient[ঃ:]?\\s*)([\\u0980-\\u09FF\\s]{1,25})', re.IGNORECASE),\n",
    "            'alternative_name': re.compile(r'([\\u0980-\\u09FF\\s]{2,20})\\s*(?:নামে|নামের)', re.IGNORECASE),\n",
    "\n",
    "            # Enhanced dosage patterns\n",
    "            'dosage': re.compile(r'(\\d+\\.?\\d*)\\s*(মিলিগ্রাম|গ্রাম|মিলি|ট্যাবলেট|ক্যাপসুল|ইউনিট)', re.IGNORECASE),\n",
    "\n",
    "            # Enhanced frequency patterns\n",
    "            'frequency': re.compile(r'(দিনে|সকালে|বিকালে|রাতে|প্রতিদিন)\\s*(\\d+)\\s*(বার|টি)|(\\d+)\\s*বার\\s*(দিনে)', re.IGNORECASE),\n",
    "\n",
    "            # Medication duration patterns (specific)\n",
    "            'medication_duration': re.compile(r'(\\d+)\\s*(দিন|সপ্তাহ|মাস)\\s*(?:খেতে|সেবন|চালিয়ে|খাবেন)', re.IGNORECASE),\n",
    "\n",
    "            # Condition duration patterns (different from medication)\n",
    "            'condition_duration': re.compile(r'(?:গত|বিগত|প্রায়)\\s*(\\d+)\\s*(দিন|সপ্তাহ|মাস|বছর)\\s*(?:ধরে|যাবত|থেকে)', re.IGNORECASE),\n",
    "\n",
    "            # Enhanced vital sign patterns\n",
    "            'temperature': re.compile(r'তাপমাত্রা[ঃ:]?\\s*(\\d+\\.?\\d*)\\s*(ডিগ্রি|°)', re.IGNORECASE),\n",
    "            'blood_pressure': re.compile(r'রক্তচাপ[ঃ:]?\\s*(\\d+)\\/(\\d+)', re.IGNORECASE),\n",
    "\n",
    "            # Enhanced demographic patterns\n",
    "            'age': re.compile(r'(\\d+)\\s*বছর\\s*বয়সী', re.IGNORECASE),\n",
    "            'weight': re.compile(r'ওজন[ঃ:]?\\s*(\\d+\\.?\\d*)\\s*(?:কেজি|কিলোগ্রাম|kg)', re.IGNORECASE),\n",
    "            'alternative_weight': re.compile(r'(\\d+\\.?\\d*)\\s*(?:কেজি|কিলোগ্রাম|kg)', re.IGNORECASE),\n",
    "\n",
    "            # Gender patterns\n",
    "            'gender': re.compile(r'(পুরুষ|মহিলা|নারী|ছেলে|মেয়ে|male|female)', re.IGNORECASE),\n",
    "\n",
    "            # Prior history patterns\n",
    "            'prior_history': re.compile(r'(?:পূর্ববর্তী|আগের|অতীতে|ইতিহাস)\\s*([^।\\.]+)', re.IGNORECASE)\n",
    "        }\n",
    "\n",
    "    def _compile_name_patterns(self) -> List[re.Pattern]:\n",
    "        \"\"\"Compile patterns for Bengali name recognition\"\"\"\n",
    "        return [\n",
    "            # Common Bengali name patterns\n",
    "            re.compile(r'\\b([\\u0980-\\u09FF]{1,15}(?:\\s+[\\u0980-\\u09FF]{1,15}){0,2})\\b'),\n",
    "            # Names with titles\n",
    "            re.compile(r'(?:জনাব|মিসেস|মিস)\\s+([\\u0980-\\u09FF\\s]{2,25})'),\n",
    "        ]\n",
    "\n",
    "    def extract_entities(self, text: str) -> Dict[str, List[Tuple[str, int, int]]]:\n",
    "        \"\"\"Enhanced extract clinical entities with positions\"\"\"\n",
    "        entities = {\n",
    "            'PATIENT_NAME': [], 'SYMPTOM': [], 'DISEASE': [], 'MEDICATION': [], 'BODY_PART': [],\n",
    "            'DOSAGE': [], 'FREQUENCY': [], 'MEDICATION_DURATION': [], 'CONDITION_DURATION': [],\n",
    "            'VITAL_SIGN': [], 'TEST': [], 'AGE': [], 'WEIGHT': [], 'GENDER': [], 'PRIOR_HISTORY': []\n",
    "        }\n",
    "\n",
    "        # Enhanced patient name extraction\n",
    "        self._extract_patient_names(text, entities)\n",
    "\n",
    "        # Enhanced dictionary-based extraction\n",
    "        self._extract_dictionary_entities(text, entities)\n",
    "\n",
    "        # Enhanced pattern-based extraction\n",
    "        self._extract_pattern_entities(text, entities)\n",
    "\n",
    "        return entities\n",
    "\n",
    "    def _extract_patient_names(self, text: str, entities: Dict):\n",
    "        \"\"\"Extract patient names more accurately\"\"\"\n",
    "        # Try main pattern first\n",
    "        name_match = self.entity_patterns['patient_name'].search(text)\n",
    "        if name_match:\n",
    "            name = name_match.group(1).strip()\n",
    "            # Validate it's actually a name (not a symptom or other text)\n",
    "            if self._is_valid_name(name):\n",
    "                entities['PATIENT_NAME'].append((name, name_match.start(1), name_match.end(1)))\n",
    "\n",
    "        # Try alternative pattern\n",
    "        if not entities['PATIENT_NAME']:\n",
    "            alt_match = self.entity_patterns['alternative_name'].search(text)\n",
    "            if alt_match:\n",
    "                name = alt_match.group(1).strip()\n",
    "                if self._is_valid_name(name):\n",
    "                    entities['PATIENT_NAME'].append((name, alt_match.start(1), alt_match.end(1)))\n",
    "\n",
    "    def _is_valid_name(self, candidate: str) -> bool:\n",
    "        \"\"\"Validate if a candidate string is actually a name\"\"\"\n",
    "        # Check if it's not a symptom, disease, or medication\n",
    "        all_medical_terms = set()\n",
    "        for category in ['symptoms', 'diseases', 'medications']:\n",
    "            all_medical_terms.update(self.lexicons[category])\n",
    "\n",
    "        # Clean candidate for comparison\n",
    "        candidate_clean = candidate.strip().lower()\n",
    "\n",
    "        # Reject if it's a known medical term\n",
    "        if candidate_clean in all_medical_terms:\n",
    "            return False\n",
    "\n",
    "        # Reject if it contains common non-name words\n",
    "        non_name_words = {'ভুগেছন', 'করেছেন', 'হয়েছে', 'আছে', 'নেই', 'করুন', 'খান'}\n",
    "        if any(word in candidate_clean for word in non_name_words):\n",
    "            return False\n",
    "\n",
    "        # Accept if it looks like a proper Bengali name\n",
    "        if re.match(r'^[\\u0980-\\u09FF\\s]{1,25}$', candidate) and len(candidate.split()) <= 3:\n",
    "            return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    def _extract_dictionary_entities(self, text: str, entities: Dict):\n",
    "        \"\"\"Extract entities using enhanced dictionary matching\"\"\"\n",
    "        words = text.split()\n",
    "        current_pos = 0\n",
    "\n",
    "        for i, word in enumerate(words):\n",
    "            word_clean = re.sub(r'[^\\u0980-\\u09FF]', '', word)\n",
    "\n",
    "            # Find position in original text\n",
    "            start_pos = text.find(word, current_pos)\n",
    "            end_pos = start_pos + len(word)\n",
    "            current_pos = end_pos\n",
    "\n",
    "            # Check for multi-word medical terms first\n",
    "            if i < len(words) - 1:\n",
    "                next_word_clean = re.sub(r'[^\\u0980-\\u09FF]', '', words[i+1])\n",
    "                two_word = f\"{word_clean} {next_word_clean}\"\n",
    "                if self._check_and_add_entity(two_word, entities, start_pos, text.find(words[i+1], end_pos) + len(words[i+1])):\n",
    "                    # Advance current_pos by the length of the second word as well\n",
    "                    current_pos += len(words[i+1])\n",
    "                    continue\n",
    "\n",
    "            # Single word matching\n",
    "            self._check_and_add_entity(word_clean, entities, start_pos, end_pos)\n",
    "\n",
    "\n",
    "    def _check_and_add_entity(self, term: str, entities: Dict, start_pos: int, end_pos: int) -> bool:\n",
    "        \"\"\"Check if term matches any lexicon and add to entities\"\"\"\n",
    "        for category, entity_type in [('symptoms', 'SYMPTOM'), ('diseases', 'DISEASE'),\n",
    "                                     ('medications', 'MEDICATION'), ('body_parts', 'BODY_PART'),\n",
    "                                     ('tests', 'TEST')]:\n",
    "            if term in self.lexicons[category]:\n",
    "                entities[entity_type].append((term, start_pos, end_pos))\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def _extract_pattern_entities(self, text: str, entities: Dict):\n",
    "        \"\"\"Extract entities using enhanced pattern matching\"\"\"\n",
    "        pattern_mappings = {\n",
    "            'dosage': 'DOSAGE',\n",
    "            'frequency': 'FREQUENCY',\n",
    "            'medication_duration': 'MEDICATION_DURATION',\n",
    "            'condition_duration': 'CONDITION_DURATION',\n",
    "            'temperature': 'VITAL_SIGN',\n",
    "            'blood_pressure': 'VITAL_SIGN',\n",
    "            'age': 'AGE',\n",
    "            'weight': 'WEIGHT',\n",
    "            'alternative_weight': 'WEIGHT',\n",
    "            'gender': 'GENDER',\n",
    "            'prior_history': 'PRIOR_HISTORY'\n",
    "        }\n",
    "\n",
    "        for pattern_name, entity_type in pattern_mappings.items():\n",
    "            pattern = self.entity_patterns[pattern_name]\n",
    "            for match in pattern.finditer(text):\n",
    "                if pattern_name in ['temperature', 'blood_pressure']:\n",
    "                    entities[entity_type].append((match.group(), match.start(), match.end()))\n",
    "                elif pattern_name == 'weight' or pattern_name == 'alternative_weight':\n",
    "                    weight_value = f\"{match.group(1)} কেজি\"\n",
    "                    entities[entity_type].append((weight_value, match.start(), match.end()))\n",
    "                elif pattern_name == 'gender':\n",
    "                    gender_bengali = self._standardize_gender(match.group(1))\n",
    "                    entities[entity_type].append((gender_bengali, match.start(), match.end()))\n",
    "                else:\n",
    "                    entities[entity_type].append((match.group(), match.start(), match.end()))\n",
    "\n",
    "    def _standardize_gender(self, gender_text: str) -> str:\n",
    "        \"\"\"Standardize gender to Bengali male/female\"\"\"\n",
    "        male_terms = ['পুরুষ', 'ছেলে', 'male']\n",
    "        female_terms = ['মহিলা', 'নারী', 'মেয়ে', 'female']\n",
    "\n",
    "        gender_lower = gender_text.lower()\n",
    "        if any(term in gender_lower for term in male_terms):\n",
    "            return 'পুরুষ'\n",
    "        elif any(term in gender_lower for term in female_terms):\n",
    "            return 'মহিলা'\n",
    "        return gender_text\n",
    "\n",
    "# ==========================================\n",
    "# SECTION 6: ENHANCED RELATION EXTRACTION\n",
    "# ==========================================\n",
    "class EnhancedClinicalRelationExtractor:\n",
    "    \"\"\"\n",
    "    Enhanced extract relationships between clinical entities with better separation of durations\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.relation_patterns = self._compile_relation_patterns()\n",
    "        self.temporal_patterns = self._compile_temporal_patterns()\n",
    "        self.medication_patterns = self._compile_medication_patterns()\n",
    "\n",
    "    def _compile_relation_patterns(self) -> Dict[str, List[re.Pattern]]:\n",
    "        \"\"\"Compile enhanced regex patterns for clinical relationships\"\"\"\n",
    "        return {\n",
    "            'symptom_of': [\n",
    "                re.compile(r'(.+?)\\s+(এর|র)\\s+লক্ষণ', re.IGNORECASE),\n",
    "                re.compile(r'(.+?)\\s+থেকে\\s+(.+?)\\s+হয়েছে', re.IGNORECASE),\n",
    "                re.compile(r'(.+?)\\s+কারণে\\s+(.+?)', re.IGNORECASE),\n",
    "                re.compile(r'(.+?)\\s+জন্য\\s+(.+?)', re.IGNORECASE)\n",
    "            ],\n",
    "            'treats': [\n",
    "                re.compile(r'(.+?)\\s+দিয়ে\\s+(.+?)\\s+চিকিৎসা', re.IGNORECASE),\n",
    "                re.compile(r'(.+?)\\s+খেলে\\s+(.+?)\\s+ভাল', re.IGNORECASE),\n",
    "                re.compile(r'(.+?)\\s+ওষুধ\\s+(.+?)\\s+জন্য', re.IGNORECASE),\n",
    "                re.compile(r'(.+?)\\s+সেবন\\s+করুন\\s+(.+?)', re.IGNORECASE)\n",
    "            ],\n",
    "            'located_in': [\n",
    "                re.compile(r'(.+?)\\s+(.+?)\\s+অংশে', re.IGNORECASE),\n",
    "                re.compile(r'(.+?)\\s+(.+?)\\s+এলাকায়', re.IGNORECASE),\n",
    "                re.compile(r'(.+?)\\s+(.+?)\\s+স্থানে', re.IGNORECASE)\n",
    "            ],\n",
    "            'has_dosage': [\n",
    "                re.compile(r'(.+?)\\s+(\\d+\\.?\\d*)\\s*(মিলিগ্রাম|গ্রাম|মিলি|ইউনিট)', re.IGNORECASE)\n",
    "            ],\n",
    "            'has_frequency': [\n",
    "                re.compile(r'(.+?)\\s+(দিনে|সকালে|বিকালে)\\s*(\\d+)\\s*বার', re.IGNORECASE),\n",
    "                re.compile(r'(.+?)\\s+(\\d+)\\s*বার\\s*(দিনে)', re.IGNORECASE)\n",
    "            ],\n",
    "            'condition_has_duration': [\n",
    "                re.compile(r'(.+?)\\s+(?:গত|বিগত|প্রায়)\\s*(\\d+)\\s*(দিন|সপ্তাহ|মাস|বছর)\\s*(?:ধরে|যাবত|থেকে)', re.IGNORECASE)\n",
    "            ],\n",
    "            'medication_has_duration': [\n",
    "                re.compile(r'(.+?)\\s+(\\d+)\\s*(দিন|সপ্তাহ|মাস)\\s*(?:খেতে|সেবন|চালিয়ে)', re.IGNORECASE)\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    def _compile_temporal_patterns(self) -> Dict[str, re.Pattern]:\n",
    "        \"\"\"Compile enhanced temporal relationship patterns\"\"\"\n",
    "        return {\n",
    "            'before': re.compile(r'(.+?)\\s+(আগে|পূর্বে)\\s+(.+?)', re.IGNORECASE),\n",
    "            'after': re.compile(r'(.+?)\\s+(পরে|পর)\\s+(.+?)', re.IGNORECASE),\n",
    "            'during': re.compile(r'(.+?)\\s+(সময়|মধ্যে)\\s+(.+?)', re.IGNORECASE),\n",
    "            'since': re.compile(r'(.+?)\\s+থেকে\\s+(.+?)', re.IGNORECASE),\n",
    "            'for_duration': re.compile(r'(.+?)\\s+(গত|বিগত)\\s+(\\d+)\\s+(দিন|সপ্তাহ|মাস|বছর)', re.IGNORECASE)\n",
    "        }\n",
    "\n",
    "    def _compile_medication_patterns(self) -> Dict[str, re.Pattern]:\n",
    "        \"\"\"Compile specific medication relationship patterns\"\"\"\n",
    "        return {\n",
    "            'medication_with_dosage': re.compile(r'([\\u0980-\\u09FF\\s]+)\\s+(\\d+\\.?\\d*)\\s*(মিলিগ্রাম|গ্রাম|মিলি|ইউনিট)', re.IGNORECASE),\n",
    "            'medication_with_frequency': re.compile(r'([\\u0980-\\u09FF\\s]+)\\s+(?:দিনে|প্রতিদিন)\\s*(\\d+)\\s*বার', re.IGNORECASE),\n",
    "            'medication_with_duration': re.compile(r'([\\u0980-\\u09FF\\s]+)\\s+(\\d+)\\s*(দিন|সপ্তাহ|মাস)\\s*(?:খেতে|সেবন)', re.IGNORECASE)\n",
    "        }\n",
    "\n",
    "    def extract_relations(self, text: str, entities: Dict) -> List[Dict]:\n",
    "        \"\"\"Extract enhanced relationships between entities\"\"\"\n",
    "        relations = []\n",
    "\n",
    "        # Extract pattern-based relations\n",
    "        for relation_type, patterns in self.relation_patterns.items():\n",
    "            for pattern in patterns:\n",
    "                matches = pattern.finditer(text)\n",
    "                for match in matches:\n",
    "                    groups = match.groups()\n",
    "                    if len(groups) >= 2:\n",
    "                        relations.append({\n",
    "                            'relation': relation_type,\n",
    "                            'arg1': groups[0].strip(),\n",
    "                            'arg2': groups[1].strip() if len(groups) > 1 else groups[0].strip(),\n",
    "                            'confidence': self._calculate_confidence(match, entities),\n",
    "                            'start': match.start(),\n",
    "                            'end': match.end(),\n",
    "                            'pattern_type': 'clinical'\n",
    "                        })\n",
    "\n",
    "        # Extract temporal relations\n",
    "        for relation_type, pattern in self.temporal_patterns.items():\n",
    "            matches = pattern.finditer(text)\n",
    "            for match in matches:\n",
    "                groups = match.groups()\n",
    "                if len(groups) >= 2:\n",
    "                    relations.append({\n",
    "                        'relation': f'temporal_{relation_type}',\n",
    "                        'arg1': groups[0].strip(),\n",
    "                        'arg2': groups[2].strip() if len(groups) > 2 else groups[1].strip(),\n",
    "                        'confidence': self._calculate_confidence(match, entities),\n",
    "                        'start': match.start(),\n",
    "                        'end': match.end(),\n",
    "                        'pattern_type': 'temporal'\n",
    "                    })\n",
    "\n",
    "        return relations\n",
    "\n",
    "    def _calculate_confidence(self, match: re.Match, entities: Dict) -> float:\n",
    "        \"\"\"Calculate confidence score for relation\"\"\"\n",
    "        matched_text = match.group()\n",
    "        entity_count = sum(\n",
    "            1 for entity_list in entities.values()\n",
    "            for entity, _, _ in entity_list\n",
    "            if entity in matched_text\n",
    "        )\n",
    "        return min(entity_count / 2.0, 1.0)\n",
    "\n",
    "    def extract_medication_relations(self, text: str, entities: Dict) -> List[Dict]:\n",
    "        \"\"\"Extract enhanced medication-related relationships\"\"\"\n",
    "        medication_relations = []\n",
    "        medications = [e[0] for e in entities.get('MEDICATION', [])]\n",
    "        dosages = [e[0] for e in entities.get('DOSAGE', [])]\n",
    "        frequencies = [e[0] for e in entities.get('FREQUENCY', [])]\n",
    "        med_durations = [e[0] for e in entities.get('MEDICATION_DURATION', [])]\n",
    "\n",
    "        for med in medications:\n",
    "            # Find closest dosage\n",
    "            for dosage in dosages:\n",
    "                if self._are_close_in_text(text, med, dosage):\n",
    "                    medication_relations.append({\n",
    "                        'relation': 'has_dosage',\n",
    "                        'medication': med,\n",
    "                        'dosage': dosage,\n",
    "                        'confidence': 0.9\n",
    "                    })\n",
    "\n",
    "            # Find closest frequency\n",
    "            for freq in frequencies:\n",
    "                if self._are_close_in_text(text, med, freq):\n",
    "                    medication_relations.append({\n",
    "                        'relation': 'has_frequency',\n",
    "                        'medication': med,\n",
    "                        'frequency': freq,\n",
    "                        'confidence': 0.9\n",
    "                    })\n",
    "\n",
    "            # Find closest medication duration (not condition duration)\n",
    "            for dur in med_durations:\n",
    "                if self._are_close_in_text(text, med, dur):\n",
    "                    medication_relations.append({\n",
    "                        'relation': 'has_medication_duration',\n",
    "                        'medication': med,\n",
    "                        'duration': dur,\n",
    "                        'confidence': 0.9\n",
    "                    })\n",
    "\n",
    "        return medication_relations\n",
    "\n",
    "    def _are_close_in_text(self, text: str, entity1: str, entity2: str, max_distance: int = 50) -> bool:\n",
    "        \"\"\"Check if two entities are close in text\"\"\"\n",
    "        pos1 = text.find(entity1)\n",
    "        pos2 = text.find(entity2)\n",
    "        if pos1 == -1 or pos2 == -1:\n",
    "            return False\n",
    "        return abs(pos1 - pos2) <= max_distance\n",
    "\n",
    "# ==========================================\n",
    "# SECTION 7: COMPLETE ENHANCED EXTRACTION PIPELINE\n",
    "# ==========================================\n",
    "class EnhancedClinicalInformationExtractor:\n",
    "    \"\"\"\n",
    "    Enhanced main class for clinical information extraction pipeline\n",
    "    \"\"\"\n",
    "    def __init__(self, model_path: Optional[str] = None, lexicon_path: Optional[str] = None):\n",
    "        self.normalizer = BanglaTextNormalizer()\n",
    "        self.tokenizer = BanglaClinicalTokenizer()\n",
    "        self.entity_recognizer = EnhancedClinicalEntityRecognizer(lexicon_path)\n",
    "        self.relation_extractor = EnhancedClinicalRelationExtractor()\n",
    "\n",
    "        # Cache for performance\n",
    "        self.cache = {}\n",
    "        self.stats = {\n",
    "            'total_requests': 0,\n",
    "            'cache_hits': 0,\n",
    "            'processing_times': []\n",
    "        }\n",
    "\n",
    "    def extract_clinical_information(self, ehr_text: str) -> Dict[str, Any]:\n",
    "        \"\"\"Enhanced main extraction pipeline\"\"\"\n",
    "        start_time = time.time()\n",
    "        self.stats['total_requests'] += 1\n",
    "\n",
    "        # Check cache\n",
    "        text_hash = hashlib.md5(ehr_text.encode()).hexdigest()\n",
    "        if text_hash in self.cache:\n",
    "            self.stats['cache_hits'] += 1\n",
    "            return self.cache[text_hash]\n",
    "\n",
    "        # Step 1: Normalize text\n",
    "        normalized_text = self.normalizer.process(ehr_text)\n",
    "\n",
    "        # Step 2: Extract entities\n",
    "        entities = self.entity_recognizer.extract_entities(normalized_text)\n",
    "\n",
    "        # Step 3: Extract relations\n",
    "        relations = self.relation_extractor.extract_relations(normalized_text, entities)\n",
    "        medication_relations = self.relation_extractor.extract_medication_relations(\n",
    "            normalized_text, entities\n",
    "        )\n",
    "\n",
    "        # Step 4: Structure information\n",
    "        structured_info = self._structure_clinical_info(\n",
    "            entities, relations + medication_relations, normalized_text\n",
    "        )\n",
    "\n",
    "        # Cache result and update stats\n",
    "        processing_time = time.time() - start_time\n",
    "        self.stats['processing_times'].append(processing_time)\n",
    "        structured_info['processing_time'] = processing_time\n",
    "        self.cache[text_hash] = structured_info\n",
    "\n",
    "        return structured_info\n",
    "\n",
    "    def _structure_clinical_info(self, entities: Dict, relations: List, text: str) -> Dict[str, Any]:\n",
    "        \"\"\"Structure extracted information into enhanced clinical format\"\"\"\n",
    "        # Extract detailed medication information\n",
    "        medication_details = self._extract_medication_details(entities, relations)\n",
    "\n",
    "        # Extract patient demographics\n",
    "        demographics = self._extract_demographics(entities, text)\n",
    "\n",
    "        # Extract vital signs with values\n",
    "        vital_signs = self._extract_vital_signs(entities, text)\n",
    "\n",
    "        # Extract diagnostic tests\n",
    "        diagnostic_tests = self._extract_diagnostic_tests(entities)\n",
    "\n",
    "        # Extract prior history\n",
    "        prior_history = self._extract_prior_history(entities, text)\n",
    "\n",
    "        return {\n",
    "            'patient_name': self._extract_patient_name(entities),\n",
    "            'age': demographics.get('age'),\n",
    "            'gender': demographics.get('gender'),\n",
    "            'weight': demographics.get('weight'),\n",
    "            'symptoms': [e[0] for e in entities.get('SYMPTOM', [])],\n",
    "            'diseases': [e[0] for e in entities.get('DISEASE', [])],\n",
    "            'medications': medication_details,\n",
    "            'duration_of_condition': self._extract_condition_duration(entities, relations),\n",
    "            'diagnostic_tests': diagnostic_tests,\n",
    "            'vital_signs': vital_signs,\n",
    "            'body_parts_mentioned': [e[0] for e in entities.get('BODY_PART', [])],\n",
    "            'prior_history': prior_history,\n",
    "            'clinical_relationships': relations,\n",
    "            'extraction_metadata': {\n",
    "                'timestamp': datetime.now().isoformat(),\n",
    "                'text_length': len(text),\n",
    "                'entity_count': sum(len(ents) for ents in entities.values()),\n",
    "                'relation_count': len(relations),\n",
    "                'confidence_score': self._calculate_overall_confidence(entities, relations)\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def _extract_patient_name(self, entities: Dict) -> Optional[str]:\n",
    "        \"\"\"Extract patient name\"\"\"\n",
    "        names = entities.get('PATIENT_NAME', [])\n",
    "        return names[0][0] if names else None\n",
    "\n",
    "    def _extract_medication_details(self, entities: Dict, relations: List) -> List[Dict]:\n",
    "        \"\"\"Extract detailed medication information with dosage, frequency, duration\"\"\"\n",
    "        medications = []\n",
    "        for med_entity in entities.get('MEDICATION', []):\n",
    "            med_name = med_entity[0]\n",
    "\n",
    "            # Initialize medication info\n",
    "            medication_info = {\n",
    "                'name': med_name,\n",
    "                'dosage': None,\n",
    "                'frequency': None,\n",
    "                'duration': None  # This is medication duration, not condition duration\n",
    "            }\n",
    "\n",
    "            # Find related information from relations\n",
    "            for relation in relations:\n",
    "                if (relation.get('medication') == med_name or\n",
    "                    relation.get('arg1') == med_name):\n",
    "                    if relation['relation'] == 'has_dosage':\n",
    "                        medication_info['dosage'] = relation.get('dosage', relation.get('arg2'))\n",
    "                    elif relation['relation'] == 'has_frequency':\n",
    "                        medication_info['frequency'] = relation.get('frequency', relation.get('arg2'))\n",
    "                    elif relation['relation'] == 'has_medication_duration':\n",
    "                        medication_info['duration'] = relation.get('duration', relation.get('arg2'))\n",
    "\n",
    "            # If no relations found, look for nearby entities\n",
    "            if not any([medication_info['dosage'], medication_info['frequency'], medication_info['duration']]):\n",
    "                # Look for dosage\n",
    "                for dosage_entity in entities.get('DOSAGE', []):\n",
    "                    if self._are_entities_related(med_name, dosage_entity[0]):\n",
    "                        medication_info['dosage'] = dosage_entity[0]\n",
    "                        break\n",
    "\n",
    "                # Look for frequency\n",
    "                for freq_entity in entities.get('FREQUENCY', []):\n",
    "                    if self._are_entities_related(med_name, freq_entity[0]):\n",
    "                        medication_info['frequency'] = freq_entity[0]\n",
    "                        break\n",
    "\n",
    "                # Look for medication duration only\n",
    "                for dur_entity in entities.get('MEDICATION_DURATION', []):\n",
    "                    if self._are_entities_related(med_name, dur_entity[0]):\n",
    "                        medication_info['duration'] = dur_entity[0]\n",
    "                        break\n",
    "\n",
    "            medications.append(medication_info)\n",
    "        return medications\n",
    "\n",
    "    def _are_entities_related(self, entity1: str, entity2: str) -> bool:\n",
    "        \"\"\"Check if two entities are likely related (simple heuristic)\"\"\"\n",
    "        # This is a simple implementation - in practice, you might want more sophisticated logic\n",
    "        return True  # For now, assume nearby entities are related\n",
    "\n",
    "    def _extract_demographics(self, entities: Dict, text: str) -> Dict[str, Any]:\n",
    "        \"\"\"Extract enhanced patient demographic information\"\"\"\n",
    "        demographics = {\n",
    "            'age': None,\n",
    "            'gender': None,\n",
    "            'weight': None\n",
    "        }\n",
    "\n",
    "        # Extract age\n",
    "        age_entities = entities.get('AGE', [])\n",
    "        if age_entities:\n",
    "            demographics['age'] = age_entities[0][0]\n",
    "\n",
    "        # Extract weight\n",
    "        weight_entities = entities.get('WEIGHT', [])\n",
    "        if weight_entities:\n",
    "            demographics['weight'] = weight_entities[0][0]\n",
    "\n",
    "        # Extract gender\n",
    "        gender_entities = entities.get('GENDER', [])\n",
    "        if gender_entities:\n",
    "            demographics['gender'] = gender_entities[0][0]\n",
    "\n",
    "        return demographics\n",
    "\n",
    "    def _extract_vital_signs(self, entities: Dict, text: str) -> List[str]:\n",
    "        \"\"\"Extract vital signs with specific values\"\"\"\n",
    "        vital_signs = []\n",
    "        for vital_entity in entities.get('VITAL_SIGN', []):\n",
    "            vital_signs.append(vital_entity[0])\n",
    "        return vital_signs\n",
    "\n",
    "    def _extract_diagnostic_tests(self, entities: Dict) -> List[str]:\n",
    "        \"\"\"Extract enhanced diagnostic tests\"\"\"\n",
    "        return [e[0] for e in entities.get('TEST', [])]\n",
    "\n",
    "    def _extract_prior_history(self, entities: Dict, text: str) -> List[str]:\n",
    "        \"\"\"Extract prior medical history\"\"\"\n",
    "        prior_history = []\n",
    "        for history_entity in entities.get('PRIOR_HISTORY', []):\n",
    "            prior_history.append(history_entity[0])\n",
    "\n",
    "        # Also look for history patterns in diseases\n",
    "        history_keywords = ['ইতিহাস', 'আগে', 'পূর্বে', 'অতীতে']\n",
    "        for disease in entities.get('DISEASE', []):\n",
    "            disease_text = disease[0]\n",
    "            # Check if disease is mentioned with history context\n",
    "            for keyword in history_keywords:\n",
    "                if keyword in text and disease_text in text:\n",
    "                    prior_history.append(f\"{disease_text} এর ইতিহাস\")\n",
    "                    break\n",
    "\n",
    "        return list(set(prior_history))  # Remove duplicates\n",
    "\n",
    "    def _extract_condition_duration(self, entities: Dict, relations: List) -> Optional[str]:\n",
    "        \"\"\"Extract duration of medical condition (separate from medication duration)\"\"\"\n",
    "        condition_durations = entities.get('CONDITION_DURATION', [])\n",
    "\n",
    "        if condition_durations:\n",
    "            return condition_durations[0][0]\n",
    "\n",
    "        # Look in relations for condition duration\n",
    "        for relation in relations:\n",
    "            if relation['relation'] == 'condition_has_duration':\n",
    "                return relation.get('arg2', '')\n",
    "\n",
    "        return None\n",
    "\n",
    "    def _calculate_overall_confidence(self, entities: Dict, relations: List) -> float:\n",
    "        \"\"\"Calculate overall confidence score for extraction\"\"\"\n",
    "        entity_count = sum(len(ents) for ents in entities.values())\n",
    "        relation_count = len(relations)\n",
    "\n",
    "        if entity_count == 0:\n",
    "            return 0.0\n",
    "\n",
    "        # Enhanced confidence calculation\n",
    "        base_confidence = min(entity_count / 10.0, 1.0)\n",
    "        relation_bonus = min(relation_count / 5.0, 0.2)\n",
    "        return min(base_confidence + relation_bonus, 1.0)\n",
    "\n",
    "    def get_stats(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get system statistics\"\"\"\n",
    "        avg_processing_time = sum(self.stats['processing_times']) / len(self.stats['processing_times']) if self.stats['processing_times'] else 0\n",
    "        return {\n",
    "            'total_requests': self.stats['total_requests'],\n",
    "            'cache_size': len(self.cache),\n",
    "            'cache_hit_ratio': self.stats['cache_hits'] / self.stats['total_requests'] if self.stats['total_requests'] > 0 else 0,\n",
    "            'avg_processing_time': avg_processing_time\n",
    "        }\n",
    "\n",
    "# ==========================================\n",
    "# SECTION 8: ENHANCED EVALUATION FRAMEWORK\n",
    "# ==========================================\n",
    "class EnhancedClinicalExtractionEvaluator:\n",
    "    \"\"\"\n",
    "    Enhanced comprehensive evaluation framework for clinical extraction system\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.metrics = {}\n",
    "\n",
    "    def evaluate_entity_extraction(self, predicted_entities: Dict, true_entities: Dict) -> Dict[str, Dict[str, float]]:\n",
    "        \"\"\"Evaluate entity extraction performance with detailed metrics\"\"\"\n",
    "        results = {}\n",
    "\n",
    "        for entity_type in set(predicted_entities.keys()) | set(true_entities.keys()):\n",
    "            # Convert to sets for comparison\n",
    "            pred_set = set(e[0] if isinstance(e, tuple) else e\n",
    "                         for e in predicted_entities.get(entity_type, []))\n",
    "            true_set = set(e[0] if isinstance(e, tuple) else e\n",
    "                         for e in true_entities.get(entity_type, []))\n",
    "\n",
    "            if len(pred_set) + len(true_set) == 0:\n",
    "                continue\n",
    "\n",
    "            # Calculate metrics\n",
    "            tp = len(pred_set & true_set)\n",
    "            fp = len(pred_set - true_set)\n",
    "            fn = len(true_set - pred_set)\n",
    "\n",
    "            precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "            recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "            f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "\n",
    "            results[entity_type] = {\n",
    "                'precision': precision,\n",
    "                'recall': recall,\n",
    "                'f1': f1,\n",
    "                'true_positives': tp,\n",
    "                'false_positives': fp,\n",
    "                'false_negatives': fn,\n",
    "                'support': len(true_set)\n",
    "            }\n",
    "\n",
    "        # Calculate macro average\n",
    "        if results:\n",
    "            macro_precision = sum(r['precision'] for r in results.values()) / len(results)\n",
    "            macro_recall = sum(r['recall'] for r in results.values()) / len(results)\n",
    "            macro_f1 = sum(r['f1'] for r in results.values()) / len(results)\n",
    "\n",
    "            results['macro_avg'] = {\n",
    "                'precision': macro_precision,\n",
    "                'recall': macro_recall,\n",
    "                'f1': macro_f1\n",
    "            }\n",
    "\n",
    "        return results\n",
    "\n",
    "    def evaluate_demographic_extraction(self, predicted: Dict, true: Dict) -> Dict[str, float]:\n",
    "        \"\"\"Evaluate demographic information extraction accuracy\"\"\"\n",
    "        demographics = ['age', 'gender', 'weight']\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for demo in demographics:\n",
    "            if demo in true:\n",
    "                total += 1\n",
    "                if demo in predicted and predicted[demo] == true[demo]:\n",
    "                    correct += 1\n",
    "\n",
    "        accuracy = correct / total if total > 0 else 0.0\n",
    "        return {'demographic_accuracy': accuracy, 'correct': correct, 'total': total}\n",
    "\n",
    "# ==========================================\n",
    "# SECTION 9: DEMONSTRATION AND TESTING\n",
    "# ==========================================\n",
    "\n",
    "# Initialize the complete system\n",
    "print(\"Initializing Complete Clinical Information Extraction System...\")\n",
    "extractor = EnhancedClinicalInformationExtractor()\n",
    "normalizer = BanglaTextNormalizer()\n",
    "tokenizer = BanglaClinicalTokenizer()\n",
    "recognizer = EnhancedClinicalEntityRecognizer()\n",
    "relation_extractor = EnhancedClinicalRelationExtractor()\n",
    "evaluator = EnhancedClinicalExtractionEvaluator()\n",
    "\n",
    "print(\"System initialized successfully!\")\n",
    "\n",
    "# ==========================================\n",
    "# TEXT NORMALIZATION DEMONSTRATION\n",
    "# ==========================================\n",
    "\n",
    "sample_texts = [\n",
    "    \"ডাঃ রহমান রাঃ ৩৫ বছর বয়সী পুরুষ জ্বর ও মাথা ব্যথায় ভুগছেন।\",\n",
    "    \"তাপমাত্রা ১০২.৫° ফারেনহাইট। পিE: সাধারণ অবস্থা ভাল।\",\n",
    "    \"এ/পি: প্যারাসিটামল ৫০০ মিগ্র দিনে ৩ বার ৫ দিন।\"\n",
    "]\n",
    "\n",
    "print(\"\\nTEXT NORMALIZATION DEMONSTRATION\")\n",
    "print(\"=\" * 50)\n",
    "for i, text in enumerate(sample_texts, 1):\n",
    "    normalized = normalizer.process(text)\n",
    "    print(f\"Original {i}: {text}\")\n",
    "    print(f\"Normalized: {normalized}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "# ==========================================\n",
    "# TOKENIZATION DEMONSTRATION\n",
    "# ==========================================\n",
    "\n",
    "test_text = \"রোগী জ্বর ও মাথাব্যথায় ভুগছেন। তাপমাত্রা ১০২.৫ ডিগ্রি। প্যারাসিটামল ৫০০ মিলিগ্রাম দিনে ৩ বার।\"\n",
    "sentences = tokenizer.segment_sentences(test_text)\n",
    "tokens = tokenizer.tokenize_words(test_text)\n",
    "\n",
    "print(\"\\nTOKENIZATION DEMONSTRATION\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Original: {test_text}\")\n",
    "print(f\"\\nSentences: {sentences}\")\n",
    "print(f\"\\nTokens: {tokens}\")\n",
    "\n",
    "# ==========================================\n",
    "# ENTITY RECOGNITION DEMONSTRATION\n",
    "# ==========================================\n",
    "\n",
    "sample_clinical_text = \"\"\"\n",
    "৩৫ বছর বয়সী পুরুষ রোগী জ্বর ও মাথাব্যথায় ভুগছেন।\n",
    "তাপমাত্রা ১০২ ডিগ্রি ফারেনহাইট। রক্তচাপ ১৪০/৯০।\n",
    "প্যারাসিটামল ৫০০ মিলিগ্রাম দিনে ৩ বার ৫ দিন সেবন করুন।\n",
    "রক্ত পরীক্ষা ও প্রস্রাব পরীক্ষা করাতে হবে।\n",
    "\"\"\"\n",
    "\n",
    "extracted_entities = recognizer.extract_entities(sample_clinical_text)\n",
    "\n",
    "print(\"\\nENTITY RECOGNITION DEMONSTRATION\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Text: {sample_clinical_text.strip()}\")\n",
    "print(\"\\nExtracted Entities:\")\n",
    "for entity_type, entities in extracted_entities.items():\n",
    "    if entities:\n",
    "        print(f\"{entity_type}: {[e[0] for e in entities]}\")\n",
    "\n",
    "# ==========================================\n",
    "# RELATION EXTRACTION DEMONSTRATION\n",
    "# ==========================================\n",
    "\n",
    "sample_relation_text = \"\"\"\n",
    "রোগী জ্বর ও মাথাব্যথায় ভুগছেন। জ্বর থেকে দুর্বলতা হয়েছে।\n",
    "প্যারাসিটামল ৫০০ মিলিগ্রাম দিনে ৩ বার ৫ দিন সেবন করুন।\n",
    "ওষুধ খাওয়ার পরে জ্বর কমবে।\n",
    "\"\"\"\n",
    "\n",
    "# Extract entities first\n",
    "sample_entities = recognizer.extract_entities(sample_relation_text)\n",
    "# Extract relations\n",
    "relations = relation_extractor.extract_relations(sample_relation_text, sample_entities)\n",
    "medication_relations = relation_extractor.extract_medication_relations(sample_relation_text, sample_entities)\n",
    "\n",
    "print(\"\\nRELATION EXTRACTION DEMONSTRATION\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Text: {sample_relation_text.strip()}\")\n",
    "print(\"\\nGeneral Relations:\")\n",
    "for rel in relations:\n",
    "    if rel['confidence'] > 0.1:  # Filter low confidence relations\n",
    "        print(f\"  {rel['relation']}: {rel['arg1']} → {rel['arg2']} (conf: {rel['confidence']:.2f})\")\n",
    "\n",
    "print(\"\\nMedication Relations:\")\n",
    "for rel in medication_relations:\n",
    "    print(f\"  {rel['relation']}: {rel['medication']} → {rel.get('dosage', rel.get('frequency', rel.get('duration', '')))}\")\n",
    "\n",
    "# ==========================================\n",
    "# COMPLETE SYSTEM DEMONSTRATION\n",
    "# ==========================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPLETE CLINICAL INFORMATION EXTRACTION DEMONSTRATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Sample clinical texts from the output document\n",
    "sample_clinical_texts = [\n",
    "    \"রোগী আব্দুর রহমান ৩৫ বছর বয়সী পুরুষ গত ২ দিন ধরে জ্বর এবং মাথাব্যথায় ভুগছেন। তাপমাত্রা ১০২ ডিগ্রি। প্যারাসিটামল ৫০০ মিলিগ্রাম দিনে ৩ বার ৩ দিন খেতে দিয়েছি।\",\n",
    "    \"রোগী ফাতিমা খাতুন ৪৫ বছর বয়সী মহিলা রক্তচাপ ১৪০/৯০। ডায়াবেটিসের ইতিহাস আছে। ওজন ৬৫ কেজি। মেটফরমিন ৫০০ মিলিগ্রাম দিনে ২ বার।\",\n",
    "    \"৮ বছর বয়সী ছেলে শিশুর গত ৩ দিন ধরে জ্বর ও কাশি। পরীক্ষা: রক্ত পরীক্ষা, এক্স রে। ওষুধ: প্যারাসিটামল ২৫০ মিলিগ্রাম দিনে ৩ বার\",\n",
    "    \"রোগী জ্বর এবং মাথাব্যথায় ভুগছেন। তাপমাত্রা ১০২ ডিগ্রি। প্যারাসিটামল ৫০০ মিলিগ্রাম দিনে ২ বার ৩ দিন খেতে দিয়েছি।\",\n",
    "    \"রক্তচাপ ১৪০/৯০। ডায়াবেটিসের ইতিহাস আছে। মেটফরমিন ৫০০ মিলিগ্রাম দিনে ২ বার।\",\n",
    "    \"পেটব্যথা এবং বমি। গত ৩ দিন ধরে সমস্যা। ওমিপ্রাজল ২০ মিলিগ্রাম সকালে খালি পেটে।\",\n",
    "    \"৪৫ বছর বয়সী মহিলা ডায়াবেটিস এবং উচ্চরক্তচাপে আক্রান্ত। ইনসুলিন ২০ ইউনিট দিনে ২ বার সকালে ও রাতে খেতে বলা হয়েছে। ওজন ৬৮ কেজি।\",\n",
    "    \"৩২ বছর বয়সী পুরুষ পেটব্যথা ও বমির জন্য ভর্তি ছিলেন। অ্যামক্সিসিলিন ৫০০ মিলিগ্রাম দিনে ৩ বার ৭ দিন সেবন করতে হয়েছে। প্রস্রাব পরীক্ষা ও আল্ট্রাসাউন্ড করানো হয়েছে।\",\n",
    "    \"৬০ বছর বয়সী পুরুষ হৃদরোগে ভুগছেন। কুইনাপ্রিল ৭৫ মিলিগ্রাম প্রতিদিন। রক্তচাপ ১৫০/১০০ mmHg.\"\n",
    "]\n",
    "\n",
    "print(\"\\nProcessing sample clinical texts:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for i, text in enumerate(sample_clinical_texts, 1):\n",
    "    print(f\"\\nDocument {i}:\")\n",
    "    print(f\"Input: {text}\")\n",
    "\n",
    "    # Extract information\n",
    "    extracted_info = extractor.extract_clinical_information(text)\n",
    "\n",
    "    # Display key information in the required format\n",
    "    print(f\"Patient Name: {extracted_info.get('patient_name', 'Not specified')}\")\n",
    "    print(f\"Age: {extracted_info.get('age', 'Not specified')}\")\n",
    "    print(f\"Symptoms: {extracted_info['symptoms']}\")\n",
    "    print(f\"Diseases: {extracted_info['diseases']}\")\n",
    "    print(f\"Medications: {extracted_info['medications']}\")\n",
    "    print(f\"Duration of Condition: {extracted_info.get('duration_of_condition', 'Not specified')}\")\n",
    "    print(f\"Diagnostic Tests: {extracted_info['diagnostic_tests']}\")\n",
    "    print(f\"Vital Signs: {extracted_info['vital_signs']}\")\n",
    "    print(f\"Processing Time: {extracted_info['processing_time']:.3f}s\")\n",
    "\n",
    "# Display system statistics\n",
    "print(f\"\\nSystem Statistics:\")\n",
    "stats = extractor.get_stats()\n",
    "for key, value in stats.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "# ==========================================\n",
    "# EVALUATION FRAMEWORK DEMO\n",
    "# ==========================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"EVALUATION FRAMEWORK DEMONSTRATION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Sample ground truth for evaluation\n",
    "ground_truth_entities = {\n",
    "    'SYMPTOM': ['জ্বর', 'মাথাব্যথা', 'পেটব্যথা', 'বমি', 'কাশি'],\n",
    "    'DISEASE': ['ডায়াবেটিস', 'হৃদরোগ'],\n",
    "    'MEDICATION': ['প্যারাসিটামল', 'মেটফরমিন', 'ইনসুলিন', 'এসপিরিন']\n",
    "}\n",
    "\n",
    "# Extract entities from first few sample texts for evaluation\n",
    "predicted_entities = {\n",
    "    'SYMPTOM': [],\n",
    "    'DISEASE': [],\n",
    "    'MEDICATION': []\n",
    "}\n",
    "\n",
    "for text in sample_clinical_texts[:4]:  # Use first 4 texts\n",
    "    entities = recognizer.extract_entities(text)\n",
    "    predicted_entities['SYMPTOM'].extend([e[0] for e in entities.get('SYMPTOM', [])])\n",
    "    predicted_entities['DISEASE'].extend([e[0] for e in entities.get('DISEASE', [])])\n",
    "    predicted_entities['MEDICATION'].extend([e[0] for e in entities.get('MEDICATION', [])])\n",
    "\n",
    "# Remove duplicates\n",
    "for key in predicted_entities:\n",
    "    predicted_entities[key] = list(set(predicted_entities[key]))\n",
    "\n",
    "# Evaluate\n",
    "evaluation_results = evaluator.evaluate_entity_extraction(predicted_entities, ground_truth_entities)\n",
    "\n",
    "print(\"\\nEntity Extraction Evaluation Results:\")\n",
    "for entity_type, metrics in evaluation_results.items():\n",
    "    if entity_type != 'macro_avg':\n",
    "        print(f\"{entity_type}: P={metrics['precision']:.3f}, R={metrics['recall']:.3f}, F1={metrics['f1']:.3f}\")\n",
    "\n",
    "if 'macro_avg' in evaluation_results:\n",
    "    macro = evaluation_results['macro_avg']\n",
    "    print(f\"macro_avg: P={macro['precision']:.3f}, R={macro['recall']:.3f}, F1={macro['f1']:.3f}\")\n",
    "\n",
    "print(\"\\nComplete Bangla Clinical Information Extraction Protocol demonstrated successfully!\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PROTOCOL SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(\"Text Normalization - Unicode, digit standardization, abbreviation expansion\")\n",
    "print(\"Clinical Tokenization - Medical compound handling, sentence segmentation\")\n",
    "print(\"Entity Recognition - Rule-based + dictionary-based extraction\")\n",
    "print(\"Relation Extraction - Clinical and temporal relationship patterns\")\n",
    "print(\"Complete Pipeline - End-to-end clinical information structuring\")\n",
    "print(\"Evaluation Framework - Precision, recall, F1-score metrics\")\n",
    "print(\"Performance Optimization - Caching, statistics tracking\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053b7ed9-c31b-44a3-af3d-d2d35eaf8f11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
